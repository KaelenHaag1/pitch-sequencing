{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac60aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8d2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Layer, MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D, Lambda, Concatenate\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbd346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Dense(ff_dim, activation=\"relu\")\n",
    "        self.out = Dense(embed_dim)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.out(ffn_output)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62976b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.pitch_tokenizer = Tokenizer()\n",
    "        self.pitch_tokenizer.fit_on_texts(df['Pitch Sequence'])\n",
    "        self.pitcher_tokenizer = Tokenizer()\n",
    "        self.pitcher_tokenizer.fit_on_texts(df['Pitcher ID'].astype(str))\n",
    "\n",
    "    def get_sequences(self):\n",
    "        return self.pitch_tokenizer.texts_to_sequences(self.df['Pitch Sequence'])\n",
    "\n",
    "    def get_pitcher_ids(self):\n",
    "        return self.pitcher_tokenizer.texts_to_sequences(self.df['Pitcher ID'].astype(str))\n",
    "\n",
    "    def pad_sequences(self, sequences, max_len=None):\n",
    "        if max_len is None:\n",
    "            max_len = max(len(seq) for seq in sequences)\n",
    "        return pad_sequences(sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42fc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchPredictionModel:\n",
    "    def __init__(self, num_tokens, num_pitchers, embedding_dim=64, num_heads=2, ff_dim=128):\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_pitchers = num_pitchers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.build_model(embedding_dim, num_heads, ff_dim)\n",
    "\n",
    "    def build_model(self, embed_dim, num_heads, ff_dim):\n",
    "        # Inputs\n",
    "        sequence_input = Input(shape=(None,), dtype=\"int64\", name=\"sequence\")\n",
    "        pitcher_input = Input(shape=(1,), dtype=\"int64\", name=\"pitcher\")\n",
    "        mask_input = Input(shape=(self.num_tokens,), dtype=\"float32\", name=\"mask\")\n",
    "\n",
    "        # Embeddings and transformer\n",
    "        embedded_sequence = Embedding(self.num_tokens, embed_dim)(sequence_input)\n",
    "        transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        transformed_sequence = transformer_block(embedded_sequence)\n",
    "\n",
    "        embedded_pitcher = Embedding(self.num_pitchers, embed_dim)(pitcher_input)\n",
    "        flat_pitcher = GlobalAveragePooling1D()(embedded_pitcher)\n",
    "\n",
    "        # Concatenate and apply mask\n",
    "        concat = Concatenate()([GlobalAveragePooling1D()(transformed_sequence), flat_pitcher])\n",
    "        logits = Dense(self.num_tokens, activation=None)(concat)\n",
    "        masked_logits = Lambda(lambda x: x[0] + (x[1] - 1) * 1e9)([logits, mask_input])\n",
    "        output = Dense(self.num_tokens, activation=\"softmax\")(masked_logits)\n",
    "\n",
    "        # Model setup\n",
    "        self.model = Model(inputs=[sequence_input, pitcher_input, mask_input], outputs=output)\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        \n",
    "    def train_test(self, sequences, pitcher_ids, masks, targets, epochs=10, batch_size=32, val_split=0.1):\n",
    "        # Splitting data into training and validation sets\n",
    "        train_seq, val_seq, train_pitcher, val_pitcher, train_mask, val_mask, train_target, val_target = \\\n",
    "            train_test_split(sequences, pitcher_ids, masks, targets, test_size=val_split, random_state=42)\n",
    "        \n",
    "        # Training the model\n",
    "        self.model.fit(\n",
    "            [train_seq, train_pitcher, train_mask], train_target,\n",
    "            validation_data=([val_seq, val_pitcher, val_mask], val_target),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "    def evaluate(self, sequences, pitcher_ids, masks, targets):\n",
    "        # Evaluate the model on a provided holdout set\n",
    "        results = self.model.evaluate([sequences, pitcher_ids, masks], targets)\n",
    "        return results\n",
    "        \n",
    "    def train(self, sequences, pitcher_ids, masks, targets, epochs=10, batch_size=32):\n",
    "        self.model.fit([sequences, pitcher_ids, masks], targets, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, sequence, pitcher_id, mask):\n",
    "        prediction = self.model.predict([sequence, pitcher_id, mask])\n",
    "        return np.argmax(prediction, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrame\n",
    "df = pd.read_csv(\"../../data/sequence_data_opt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a15e033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pitch Sequence</th>\n",
       "      <th>Pitcher ID</th>\n",
       "      <th>At-Bat Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI</td>\n",
       "      <td>621107</td>\n",
       "      <td>field_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI,CB,FC,SI,CB,SI,FF</td>\n",
       "      <td>621107</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST,ST,SI,SI,ST,ST</td>\n",
       "      <td>676534</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI,ST,SI,ST,SI</td>\n",
       "      <td>687330</td>\n",
       "      <td>grounded_into_double_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF,FF,FF,SL,FF,SL</td>\n",
       "      <td>477132</td>\n",
       "      <td>strikeout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pitch Sequence  Pitcher ID             At-Bat Outcome\n",
       "0                    SI      621107                field_error\n",
       "1  SI,CB,FC,SI,CB,SI,FF      621107                     single\n",
       "2     ST,ST,SI,SI,ST,ST      676534                       walk\n",
       "3        SI,ST,SI,ST,SI      687330  grounded_into_double_play\n",
       "4     FF,FF,FF,SL,FF,SL      477132                  strikeout"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess data\n",
    "\n",
    "sequences = preprocessor.get_sequences()\n",
    "pitcher_ids = preprocessor.get_pitcher_ids()\n",
    "padded_sequences = preprocessor.pad_sequences(sequences)\n",
    "\n",
    "# Prepare targets (for training, assume predicting next pitch type in sequence)\n",
    "targets = np.array([seq[1:] + [0] for seq in sequences])\n",
    "\n",
    "# Initialize and train the model\n",
    "model = PitchPredictionModel(num_tokens=len(preprocessor.pitch_tokenizer.word_index) + 1,\n",
    "                             num_pitchers=len(preprocessor.pitcher_tokenizer.word_index) + 1,\n",
    "                             embedding_dim=64, num_heads=2, ff_dim=128)\n",
    "model.train(padded_sequences, pitcher_ids, targets, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
