{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4d1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f080bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Layer, MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D, Lambda, Concatenate\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ffb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Dense(ff_dim, activation=\"relu\")\n",
    "        self.out = Dense(embed_dim)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.out(ffn_output)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00304a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, sequences, pitcher_ids):\n",
    "        self.pitch_tokenizer = Tokenizer(filters='', split=',')\n",
    "        self.pitch_tokenizer.fit_on_texts(sequences)\n",
    "        self.pitcher_tokenizer = Tokenizer()\n",
    "        self.pitcher_tokenizer.fit_on_texts(map(str, pitcher_ids))\n",
    "\n",
    "    def tokenize_sequences(self, sequences):\n",
    "        return self.pitch_tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "    def tokenize_pitchers(self, pitcher_ids):\n",
    "        return self.pitcher_tokenizer.texts_to_sequences(map(str, pitcher_ids))\n",
    "\n",
    "    def pad_sequences(self, sequences):\n",
    "        max_len = max(len(seq) for seq in sequences)\n",
    "        return pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "    def create_pitcher_pitch_mask(self, sequences, pitcher_ids):\n",
    "        num_pitchers = len(self.pitcher_tokenizer.word_index) + 1\n",
    "        num_tokens = len(self.pitch_tokenizer.word_index) + 1\n",
    "        pitcher_pitch_mask = np.zeros((num_pitchers, num_tokens))\n",
    "        for pitcher_id, sequence in zip(pitcher_ids, sequences):\n",
    "            tokenized_pitcher_id = self.pitcher_tokenizer.texts_to_sequences([str(pitcher_id)])[0][0]\n",
    "            tokenized_sequence = self.pitch_tokenizer.texts_to_sequences([sequence])[0]\n",
    "            pitcher_pitch_mask[tokenized_pitcher_id, tokenized_sequence] = 1\n",
    "        return pitcher_pitch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd9542be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the `PitchPredictionModel` has already been defined and uses the custom TransformerBlock\n",
    "class PitchPredictionModel:\n",
    "    def __init__(self, num_tokens, num_pitchers, embedding_dim=64, num_heads=2, ff_dim=128):\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_pitchers = num_pitchers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.build_model(embedding_dim, num_heads, ff_dim)\n",
    "\n",
    "    def build_model(self, embed_dim, num_heads, ff_dim):\n",
    "        sequence_input = Input(shape=(None,), dtype=\"int64\", name=\"sequence\")\n",
    "        pitcher_input = Input(shape=(1,), dtype=\"int64\", name=\"pitcher\")\n",
    "        mask_input = Input(shape=(self.num_tokens,), dtype=\"float32\", name=\"mask\")\n",
    "\n",
    "        embedded_sequence = Embedding(self.num_tokens, embed_dim, mask_zero=True)(sequence_input)\n",
    "        transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        transformed_sequence = transformer_block(embedded_sequence)\n",
    "\n",
    "        embedded_pitcher = Embedding(self.num_pitchers, embed_dim)(pitcher_input)\n",
    "        flat_pitcher = GlobalAveragePooling1D()(embedded_pitcher)\n",
    "\n",
    "        concat = Concatenate()([GlobalAveragePooling1D()(transformed_sequence), flat_pitcher])\n",
    "        logits = Dense(self.num_tokens, activation=None)(concat)\n",
    "        masked_logits = Lambda(lambda x: x[0] + (x[1] - 1) * 1e9)([logits, mask_input])\n",
    "        output = Dense(self.num_tokens, activation=\"softmax\")(masked_logits)\n",
    "\n",
    "        self.model = Model(inputs=[sequence_input, pitcher_input, mask_input], outputs=output)\n",
    "        self.model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    def train_test(self, sequences, pitcher_ids, masks, targets, epochs=10, batch_size=32, val_split=0.1):\n",
    "        # Splitting data into training and validation sets\n",
    "        train_seq, val_seq, train_pitcher, val_pitcher, train_mask, val_mask, train_target, val_target = \\\n",
    "            train_test_split(sequences, pitcher_ids, masks, targets, test_size=val_split, random_state=42)\n",
    "        \n",
    "        # Training the model\n",
    "        self.model.fit(\n",
    "            [train_seq, train_pitcher, train_mask], train_target,\n",
    "            validation_data=([val_seq, val_pitcher, val_mask], val_target),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    def evaluate(self, sequences, pitcher_ids, masks, targets):\n",
    "        # Evaluate the model on a provided holdout set\n",
    "        results = self.model.evaluate([sequences, pitcher_ids, masks], targets)\n",
    "        return results\n",
    "        \n",
    "    def train(self, sequences, pitcher_ids, masks, targets, epochs=10, batch_size=32):\n",
    "        self.model.fit([sequences, pitcher_ids, masks], targets, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, sequence, pitcher_id, mask):\n",
    "        prediction = self.model.predict([sequence, pitcher_id, mask])\n",
    "        return np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f95af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrame\n",
    "df = pd.read_csv(\"../../data/sequence_data_opt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fcc490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pitch Sequence</th>\n",
       "      <th>Pitcher ID</th>\n",
       "      <th>At-Bat Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI</td>\n",
       "      <td>621107</td>\n",
       "      <td>field_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI,CB,FC,SI,CB,SI,FF</td>\n",
       "      <td>621107</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST,ST,SI,SI,ST,ST</td>\n",
       "      <td>676534</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI,ST,SI,ST,SI</td>\n",
       "      <td>687330</td>\n",
       "      <td>grounded_into_double_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FF,FF,FF,SL,FF,SL</td>\n",
       "      <td>477132</td>\n",
       "      <td>strikeout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pitch Sequence  Pitcher ID             At-Bat Outcome\n",
       "0                    SI      621107                field_error\n",
       "1  SI,CB,FC,SI,CB,SI,FF      621107                     single\n",
       "2     ST,ST,SI,SI,ST,ST      676534                       walk\n",
       "3        SI,ST,SI,ST,SI      687330  grounded_into_double_play\n",
       "4     FF,FF,FF,SL,FF,SL      477132                  strikeout"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d8747b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(df['Pitch Sequence'], df['Pitcher ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e1ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sequences = preprocessor.tokenize_sequences(df['Pitch Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6722370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = preprocessor.pad_sequences(tokenized_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9e36a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_pitchers = preprocessor.tokenize_pitchers(df['Pitcher ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0783c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitcher_masks = preprocessor.create_pitcher_pitch_mask(df['Pitch Sequence'], df['Pitcher ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "667e8b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0, ..., 0, 0, 0],\n",
       "       [3, 5, 6, ..., 0, 0, 0],\n",
       "       [7, 7, 3, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [7, 7, 7, ..., 0, 0, 0],\n",
       "       [1, 8, 2, ..., 0, 0, 0],\n",
       "       [5, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48634a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the targets for training: next pitch in the sequence\n",
    "targets = np.array([seq[1:] + [0] for seq in padded_sequences])  # Assuming this simple target preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = PitchPredictionModel(\n",
    "    num_tokens=len(preprocessor.pitch_tokenizer.word_index) + 1,\n",
    "    num_pitchers=len(preprocessor.pitcher_tokenizer.word_index) + 1,\n",
    "    embedding_dim=64, num_heads=2, ff_dim=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train(padded_sequences, tokenized_pitchers, pitcher_masks, targets, epochs=10, batch_size=32, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf20089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluation_results = model.evaluate(padded_sequences, tokenized_pitchers, pitcher_masks, targets)\n",
    "print(\"Evaluation results:\", evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
